{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55a306f4",
   "metadata": {},
   "source": [
    "Originally `duration-prediction.ipynb` from Module 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2bd82d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'DOSKEY' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41062d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import mlflow\n",
    "import xgboost as xgb\n",
    "from prefect import task , flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4add538c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ikram\\anaconda3\\envs\\mlops_perfect\\lib\\site-packages\\prefect\\tasks.py:326: UserWarning: A task named 'is_odd_or_even' and defined at 'C:\\Users\\Ikram\\AppData\\Local\\Temp\\ipykernel_14076\\157532722.py:1' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n",
      "\n",
      " `@task(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "@task(retries=4 ,retry_delay_seconds=2, log_prints=True )\n",
    "def is_odd_or_even(list_name: list) -> list :\n",
    "    \"\"\"Function taking a list as input to check if numbers in it are even or odd and returns \n",
    "       a list of checked results \"\"\"\n",
    "    print(f\"The list is {list_name}\")\n",
    "    for number in list_name : \n",
    "        if number %2 == 0 :\n",
    "            print(f\"The number {number} is even\")\n",
    "        else:\n",
    "            print(f\"The number {number} is odd\")\n",
    "    list_checked_even_odd = [number for number in list_name if number %2 == 0 ]\n",
    "    return list_checked_even_odd\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1464985f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ikram\\anaconda3\\envs\\mlops_perfect\\lib\\site-packages\\prefect\\tasks.py:326: UserWarning: A task named 'multiply_values_by_2' and defined at 'C:\\Users\\Ikram\\AppData\\Local\\Temp\\ipykernel_14076\\1344228005.py:1' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n",
      "\n",
      " `@task(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "@task\n",
    "def multiply_values_by_2(list_name: list) -> list:\n",
    "    \"\"\"Function that takes a list and multiplies by 2 all elements\"\"\"\n",
    "    multiplied = [number *2 for number in list_name]\n",
    "    return multiplied\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7c4c4a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task(retries=4 ,retry_delay_seconds=2 )\n",
    "def divide_by_3(list_name: list) -> tuple:\n",
    "    \"\"\" Function that takes a list and divides every item by 3 \"\"\"\n",
    "    divided_tuple= tuple ([number / 3 for number in numbers])\n",
    "    return divided_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "eecba504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ikram\\anaconda3\\envs\\mlops_perfect\\lib\\site-packages\\prefect\\flows.py:273: UserWarning: A flow named 'main-flow' and defined at 'C:\\Users\\Ikram\\AppData\\Local\\Temp\\ipykernel_14076\\3869034176.py:2' conflicts with another flow. Consider specifying a unique `name` parameter in the flow definition:\n",
      "\n",
      " `@flow(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "numbers= [0,1,23,45,9,20,460]\n",
    "@flow(flow_run_name= \"Zied_MLOps_Perfect_Orchestration\" , log_prints=True)\n",
    "def main_flow():\n",
    "    \"\"\"The main Pipeline\"\"\"\n",
    "    list_checked_even_odd = is_odd_or_even(list_name=numbers)\n",
    "    multiplied = multiply_values_by_2(list_name=list_checked_even_odd)\n",
    "    divided_tuple = divide_by_3(list_name=multiplied)\n",
    "    \n",
    "    return (f\"The final checked and divided tuple is {divided_tuple}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e83f6e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:21:19.731 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'tungsten-kagu'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'main-flow'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:21:19.731 | \u001b[36mINFO\u001b[0m    | prefect.engine - Created flow run\u001b[35m 'tungsten-kagu'\u001b[0m for flow\u001b[1;35m 'main-flow'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:21:19.737 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'tungsten-kagu'</span> - View at <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:4200/flow-runs/flow-run/22ba4932-dc71-4aa8-87ff-013423c4219d</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:21:19.737 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'tungsten-kagu'\u001b[0m - View at \u001b[94mhttp://127.0.0.1:4200/flow-runs/flow-run/22ba4932-dc71-4aa8-87ff-013423c4219d\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:21:20.538 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'Zied_MLOps_Perfect_Orchestration'</span> - Created task run 'is_odd_or_even-0' for task 'is_odd_or_even'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:21:20.538 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'Zied_MLOps_Perfect_Orchestration'\u001b[0m - Created task run 'is_odd_or_even-0' for task 'is_odd_or_even'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:21:20.542 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'Zied_MLOps_Perfect_Orchestration'</span> - Executing 'is_odd_or_even-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:21:20.542 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'Zied_MLOps_Perfect_Orchestration'\u001b[0m - Executing 'is_odd_or_even-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:21:22.373 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'is_odd_or_even-0' - The list is [0, 1, 23, 45, 9, 20, 460]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:21:22.373 | \u001b[36mINFO\u001b[0m    | Task run 'is_odd_or_even-0' - The list is [0, 1, 23, 45, 9, 20, 460]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:21:22.380 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'is_odd_or_even-0' - The number 0 is even\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:21:22.380 | \u001b[36mINFO\u001b[0m    | Task run 'is_odd_or_even-0' - The number 0 is even\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:21:22.386 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'is_odd_or_even-0' - The number 1 is odd\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:21:22.386 | \u001b[36mINFO\u001b[0m    | Task run 'is_odd_or_even-0' - The number 1 is odd\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:21:22.391 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'is_odd_or_even-0' - The number 23 is odd\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:21:22.391 | \u001b[36mINFO\u001b[0m    | Task run 'is_odd_or_even-0' - The number 23 is odd\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:21:22.395 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'is_odd_or_even-0' - The number 45 is odd\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:21:22.395 | \u001b[36mINFO\u001b[0m    | Task run 'is_odd_or_even-0' - The number 45 is odd\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:21:22.403 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'is_odd_or_even-0' - The number 9 is odd\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:21:22.403 | \u001b[36mINFO\u001b[0m    | Task run 'is_odd_or_even-0' - The number 9 is odd\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:21:22.407 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'is_odd_or_even-0' - The number 20 is even\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:21:22.407 | \u001b[36mINFO\u001b[0m    | Task run 'is_odd_or_even-0' - The number 20 is even\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:21:22.412 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'is_odd_or_even-0' - The number 460 is even\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:21:22.412 | \u001b[36mINFO\u001b[0m    | Task run 'is_odd_or_even-0' - The number 460 is even\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:21:23.059 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'is_odd_or_even-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:21:23.059 | \u001b[36mINFO\u001b[0m    | Task run 'is_odd_or_even-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:21:23.750 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'Zied_MLOps_Perfect_Orchestration'</span> - Created task run 'multiply_values_by_2-0' for task 'multiply_values_by_2'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:21:23.750 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'Zied_MLOps_Perfect_Orchestration'\u001b[0m - Created task run 'multiply_values_by_2-0' for task 'multiply_values_by_2'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:21:23.752 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'Zied_MLOps_Perfect_Orchestration'</span> - Executing 'multiply_values_by_2-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:21:23.752 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'Zied_MLOps_Perfect_Orchestration'\u001b[0m - Executing 'multiply_values_by_2-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:21:25.624 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'multiply_values_by_2-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:21:25.624 | \u001b[36mINFO\u001b[0m    | Task run 'multiply_values_by_2-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:21:26.935 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'Zied_MLOps_Perfect_Orchestration'</span> - Created task run 'divide_by_3-0' for task 'divide_by_3'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:21:26.935 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'Zied_MLOps_Perfect_Orchestration'\u001b[0m - Created task run 'divide_by_3-0' for task 'divide_by_3'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:21:26.938 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'Zied_MLOps_Perfect_Orchestration'</span> - Executing 'divide_by_3-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:21:26.938 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'Zied_MLOps_Perfect_Orchestration'\u001b[0m - Executing 'divide_by_3-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:21:28.674 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'divide_by_3-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:21:28.674 | \u001b[36mINFO\u001b[0m    | Task run 'divide_by_3-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:21:29.542 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'tungsten-kagu'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:21:29.542 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'tungsten-kagu'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3b13ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = [1,3,6,8,7]\n",
    "numbers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2eb3d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 8]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = range(1,11)\n",
    "pair = [number for number in numbers if number % 2 == 0]\n",
    "pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b5f5fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f21a0ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "from flask_cors import CORS\n",
    "from flask import Flask, redirect, url_for, request, render_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fb45da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_a_flask_app() -> Flask:\n",
    "    \"\"\" \n",
    "    Creates a Flask app instance synchronized with a CORS feature allowing\n",
    "    serving resources to clients and unrestricted communication between web application and API \n",
    "     \n",
    "    Input : None\n",
    "    \n",
    "    Returns:\n",
    "        Flask : a Flask app instance \n",
    "     \"\"\"\n",
    "     \n",
    "    # Creating the Flask app instance\n",
    "    app = Flask(__name__)\n",
    "    \n",
    "    # Enable the CORS Feature for the created app:\n",
    "    CORS(app)\n",
    "    return app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f298f219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_a_flask_app() -> Flask:\n",
    "    \"\"\" \n",
    "    Creates a Flask app instance synchronized with a CORS feature allowing\n",
    "    serving resources to clients and unrestricted communication between web application and API \n",
    "     \n",
    "    Parameters : None\n",
    "    \n",
    "    Returns:\n",
    "        Flask : a Flask app instance \n",
    "     \"\"\"\n",
    "     \n",
    "    # Creating the Flask app instance\n",
    "    app = Flask(__name__)\n",
    "    \n",
    "    # Enable the CORS Feature for the created app:\n",
    "    CORS(app)\n",
    "    return app\n",
    "\n",
    "\n",
    "# Calling the Flask app :\n",
    "app = create_a_flask_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecf223a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_the_Deployment_Model(Model_Path: str) -> \"keras.models.Model\":\n",
    "    \"\"\"\n",
    "    Loads the trained Keras Model from the specified path \n",
    "    \n",
    "    Parameters:\n",
    "        Model_Path: The path where the Keras Model is saved in a HDF5 Format\n",
    "        \n",
    "    Returns:\n",
    "        keras.models.Model: The Loaded Trained Keras Model\n",
    "        \n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the trained Model:\n",
    "        model = load_model(Model_Path)\n",
    "        return model\n",
    "    \n",
    "    except OSError as error :\n",
    "        raise OSError(f\"The model was not found on the specified path: {Model_Path}\") from error\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64224829",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "The Numpy data was not found on the specified path: ./X_train.npy",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 14\u001b[0m, in \u001b[0;36mLoad_The_Train_Data\u001b[1;34m(File_Path)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     \u001b[39m# Load the trained Model:\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     training_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(File_Path)\n\u001b[0;32m     15\u001b[0m     \u001b[39mreturn\u001b[39;00m training_data\n",
      "File \u001b[1;32mc:\\Users\\Ikram\\anaconda3\\envs\\mlops_perfect\\lib\\site-packages\\numpy\\lib\\npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 405\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m    406\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './X_train.npy'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39m# Loading the Numpy training data :\u001b[39;00m\n\u001b[0;32m     21\u001b[0m Path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./X_train.npy\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 22\u001b[0m X_train \u001b[39m=\u001b[39m Load_The_Train_Data(File_Path\u001b[39m=\u001b[39;49mPath)\n",
      "Cell \u001b[1;32mIn[25], line 18\u001b[0m, in \u001b[0;36mLoad_The_Train_Data\u001b[1;34m(File_Path)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[39mreturn\u001b[39;00m training_data\n\u001b[0;32m     17\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m error :\n\u001b[1;32m---> 18\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe Numpy data was not found on the specified path: \u001b[39m\u001b[39m{\u001b[39;00mFile_Path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merror\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: The Numpy data was not found on the specified path: ./X_train.npy"
     ]
    }
   ],
   "source": [
    "\n",
    "def Load_The_Train_Data(File_Path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Loads the training data X_train stored in a Numpy file\n",
    "    \n",
    "    Parameters:\n",
    "        File_Path: The path where the training data X_train is stored\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: The Loaded Training data into a numpy array\n",
    "        \n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the trained Model:\n",
    "        training_data = np.load(File_Path)\n",
    "        return training_data\n",
    "    \n",
    "    except OSError as error :\n",
    "        raise OSError(f\"The Numpy data was not found on the specified path: {File_Path}\") from error\n",
    "    \n",
    "# Loading the Numpy training data :\n",
    "Path = \"./X_train.npy\"\n",
    "X_train = Load_The_Train_Data(File_Path=Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6675b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c10d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fitting_MinMax_Training_Data(X_train: np.ndarray) -> MinMaxScaler:\n",
    "    \"\"\"\n",
    "    Fit the MinMaxScaler to the training data \n",
    "    \n",
    "    Parameters:\n",
    "        X_train : The numpy array training data\n",
    "        \n",
    "    Returns:\n",
    "        MinMaxScaler : The MinMaxScaler object fitted to the training data\"\"\"\n",
    "        \n",
    "    #Create the MinMaxScaler Instance : \n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Fit the MinMaxScaler to the training data X_train :\n",
    "    scaler.fit(X_train)\n",
    "        \n",
    "    return scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7a85fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/predict', methods=['GET', 'POST'])\n",
    "def upload_and_predict() -> str:\n",
    "    \"\"\"\n",
    "   Manages the upload of audio data and predicts the label through:\n",
    "  \n",
    "   1* Being launched when a POST request with a file associated is received\n",
    "     from the Front-End interface\n",
    "  \n",
    "   2* Saving the uploaded data into the './uploads' directory\n",
    "  \n",
    "   3* Saving the string path where the data is saved in the uploads folder  \n",
    "  \n",
    "   Input :\n",
    "        None\n",
    "  \n",
    "   Parameters:\n",
    "        None\n",
    "\n",
    "   Returns:\n",
    "        file_path: a string of the path where the uploaded audio data is saved     \n",
    "   \"\"\"\n",
    "    if request.method == 'POST':\n",
    "      \n",
    "        # Get the file from post request\n",
    "        f = request.files['t1']\n",
    "\n",
    "        # Create the Save the file to ./uploads\n",
    "        basepath = os.path.dirname(__file__)\n",
    "        file_path = os.path.join(basepath, 'uploads', secure_filename(f.filename))\n",
    "        f.save(file_path)\n",
    "        \n",
    "        return file_path\n",
    "      \n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aedbce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25c475f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc92c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_single = [[0.2, 0.1, 0.5, 0.2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d76bf2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2, 0.1, 0.5, 0.2]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_single[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33bb0f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  --> Code Downgraded on 22/07/2023 : Replaced by loading from model registry\\n\\ndef Load_the_Deployment_Model(Model_Path: str) -> \"keras.models.Model\":\\n    \"\"\"    \\n    Loads the trained Keras Model from the specified path \\n    \\n    Parameters:\\n        Model_Path: The path where the Keras Model is saved in a HDF5 Format\\n        \\n    Returns:\\n        keras.models.Model: The Loaded Trained Keras Model\\n        \\n    \"\"\"\\n    try:\\n        # Load the trained Model:\\n        model = load_model(Model_Path)\\n        return model\\n    \\n    except OSError as error :\\n        raise OSError(f\"The model was not found on the specified path: {Model_Path}\") from error\\n        \\n\\n# Loading the Trained Keras Model :\\nMODEL_PATH = \"./Respiratory_CNN_1D_Model.hdf5\"\\nmodel = Load_the_Deployment_Model(Model_Path=MODEL_PATH)        \\n\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''  --> Code Downgraded on 22/07/2023 : Replaced by loading from model registry\n",
    "\n",
    "def Load_the_Deployment_Model(Model_Path: str) -> \"keras.models.Model\":\n",
    "    \"\"\"    \n",
    "    Loads the trained Keras Model from the specified path \n",
    "    \n",
    "    Parameters:\n",
    "        Model_Path: The path where the Keras Model is saved in a HDF5 Format\n",
    "        \n",
    "    Returns:\n",
    "        keras.models.Model: The Loaded Trained Keras Model\n",
    "        \n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the trained Model:\n",
    "        model = load_model(Model_Path)\n",
    "        return model\n",
    "    \n",
    "    except OSError as error :\n",
    "        raise OSError(f\"The model was not found on the specified path: {Model_Path}\") from error\n",
    "        \n",
    "\n",
    "# Loading the Trained Keras Model :\n",
    "MODEL_PATH = \"./Respiratory_CNN_1D_Model.hdf5\"\n",
    "model = Load_the_Deployment_Model(Model_Path=MODEL_PATH)        \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1869eb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a205e13",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "The model was not found on the specified path: dhf/df",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 14\u001b[0m, in \u001b[0;36mLoad_the_Deployment_Model\u001b[1;34m(Model_Path)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     \u001b[39m# Load the trained Model:\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     model \u001b[39m=\u001b[39m load_model(Model_Path)\n\u001b[0;32m     15\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\Ikram\\anaconda3\\envs\\mlops_perfect\\lib\\site-packages\\keras\\src\\saving\\saving_api.py:238\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39m# Legacy case.\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m \u001b[39mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[39m.\u001b[39mload_model(\n\u001b[0;32m    239\u001b[0m     filepath, custom_objects\u001b[39m=\u001b[39mcustom_objects, \u001b[39mcompile\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcompile\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    240\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Ikram\\anaconda3\\envs\\mlops_perfect\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Ikram\\anaconda3\\envs\\mlops_perfect\\lib\\site-packages\\keras\\src\\saving\\legacy\\save.py:234\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 234\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[0;32m    235\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    236\u001b[0m     )\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at dhf/df",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Load_the_Deployment_Model(Model_Path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdhf/df\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[21], line 18\u001b[0m, in \u001b[0;36mLoad_the_Deployment_Model\u001b[1;34m(Model_Path)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[0;32m     17\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m error :\n\u001b[1;32m---> 18\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe model was not found on the specified path: \u001b[39m\u001b[39m{\u001b[39;00mModel_Path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merror\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: The model was not found on the specified path: dhf/df"
     ]
    }
   ],
   "source": [
    "Load_the_Deployment_Model(Model_Path=\"dhf/df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4051943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0848c9d6c7d415ad6c477ff7ff8e98694d1a4aa96d0deee89244642e6b630036"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
